from src.data_preprocessing import load_and_clean_data, auto_select_seq_len
from src.dataset_builder import create_dataset
from models import build_models
from src.train import train_model
from src.evaluate import (
    evaluate_model,
    plot_rolling_predictions_all_features,
    save_last_days_results_to_csv,
    save_initial_sequence_to_csv
)
from sklearn.preprocessing import MinMaxScaler
import torch
import os
import pandas as pd

# ----------------- å…¨å±€é…ç½® -----------------

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_PATH = os.path.join(BASE_DIR, "data", "data.csv")
FUTURE_DAYS = 5
TARGET_FEATURE_INDEX = 5
BATCH_SIZE = 32
EPOCHS = 3
LEARNING_RATE = 0.01

def main():
    os.makedirs("outputs", exist_ok=True)
    os.makedirs("src/models/saved_models", exist_ok=True)

    # 1. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
    selected_columns = input("è¯·è¾“å…¥è¦å±•ç¤ºçš„åˆ—åï¼ˆé€—å·åˆ†éš”ï¼‰: ")
    data, dataset, scaler = load_and_clean_data(DATA_PATH, selected_columns)
    input_size = dataset.shape[1]

    # 2. æ„å»ºæ•°æ®é›†
    seq_len = auto_select_seq_len(input_size)
    train_size = int(len(dataset) * 0.8)
    train, test = dataset[:train_size], dataset[train_size:]
    trainX, trainY = create_dataset(train, seq_len)
    testX, testY = create_dataset(test, seq_len)

    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(trainX, trainY), batch_size=BATCH_SIZE, shuffle=False)
    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(testX, testY), batch_size=BATCH_SIZE, shuffle=False)

    # 3. æ¨¡å‹æ„å»ºä¸åŠ è½½/è®­ç»ƒ
    models = build_models(input_size)
    trained_models = {}
    all_train_losses = {}

    for name, model in models.items():
        model_path = f"src/models/saved_models/{name}.pth"

        if os.path.exists(model_path):
            print(f"âœ… æ£€æµ‹åˆ°å·²ä¿å­˜æ¨¡å‹ï¼ŒåŠ è½½ï¼š{model_path}")
            model.load_state_dict(torch.load(model_path, weights_only=True))
            trained_models[name] = model
        else:
            print(f"ğŸš€ æœªæ£€æµ‹åˆ°æ¨¡å‹ï¼Œå¼€å§‹è®­ç»ƒ: {name}")
            trained, losses = train_model(model, name, train_loader, EPOCHS, LEARNING_RATE)
            trained_models[name] = trained
            all_train_losses[name] = losses
            torch.save(trained.state_dict(), model_path)
            print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")

    # 4. æ¨¡å‹è¯„ä¼°
    evaluation_results = []
    for name, model in trained_models.items():
        result = evaluate_model(model, name, test_loader, scaler, TARGET_FEATURE_INDEX, dataset.shape[1])
        evaluation_results.append(result)

    eval_df = pd.DataFrame(evaluation_results)
    eval_df.to_csv("outputs/model_evaluation_results.csv", index=False)
    print("ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœå·²ä¿å­˜ï¼šoutputs/model_evaluation_results.csv")

    # 5. æ»šåŠ¨é¢„æµ‹ + å¯è§†åŒ–
    rolling_predictions_all_models = {}
    real_values_all_models = {}
    initial_index_ranges = {}

    for name, model in trained_models.items():
        preds, real_values, index_range = plot_rolling_predictions_all_features(
            model, name, test, scaler, seq_len, FUTURE_DAYS, TARGET_FEATURE_INDEX, dataset.shape[1]
        )
        rolling_predictions_all_models[name] = preds
        real_values_all_models[name] = real_values
        initial_index_ranges[name] = index_range

    save_last_days_results_to_csv(rolling_predictions_all_models, real_values_all_models, initial_index_ranges, FUTURE_DAYS)
    save_initial_sequence_to_csv(test, list(initial_index_ranges.values())[0], seq_len, scaler, dataset.shape[1])
    print("ğŸ“ æ»šåŠ¨é¢„æµ‹ç»“æœä¸åˆå§‹åºåˆ—å·²ä¿å­˜è‡³ outputs ç›®å½•")

if __name__ == '__main__':
    main()
